데이터 분석(Data Analysis)
: 데이터로부터 의미 있는 인사이트를 도출하기 위한 과정 

데이터 분석 프로세스
: 문제정의 > 데이터 수집 > 데이터 정제 및 전처리 > 데이터 탐색 > 결과 해석/검증 > 의사결정 


** 데이터 수집 **
- 데이터 수집 : 분석에 필요한 데이터를 다양한 고셍서 수집하여 통합하는 과정
- 데이터 수집 종류 :  내부 데이터 (DB) / 외부 데이터 (크롤링, API) (그외에도 다양하게 방법 존재)
- 데이터 수집 중요성 : 파이프라인 앞단의 데이터 수집이 잘못되면 뒷단 전체에 영향을 줌 > 필요한 것만 정확히 수집


** 웹 크롤링 ** 
: 인터넷 상의 웹 페이지를 자동으로 탐색하고 데이터를 수집하는 기술
> 크롤링하는 웹 페이지는 HTML라는 마크업 언어로 구성 
> 원하는 주소의 웹페이지로 이동하여 HTML을 가져오고 원하는 데이터가 어디 있는지 가져옴 (Parsing)

** 웹 크롤링의 장점 **
- 공식적인 API가 없거나 제한적인 경우 유용
- 자동화 / 대량 데이터 수집 / 구조화된 데이터 추출


** 웹 크롤링 주의사항 **
- 이용 목적 투명성 : 개인 학습 및 연구 목적 외, 영리적/상업적으로 활용하거나 동의 없이 무단으로 복제하는 경우.
저작권 침해로 간주됨, 이용약관 숙지
- robots.txt 존중 : 웹 사이트 봇(bot)이 무단으로 접근하는 것을 방지, 크롤러가 접근해도 경로를 robots.txt파일에 명시
- 서버에 부하를 주지 않을 것 : 짧은 시간에 수백 수천건의 요청을 보내면 서비스 마비 가능, 요청 간 시간 지연 필수 

** 크롤링에 필요한 요소 **
(1) Request 라이브러리 : 접근할 웹 페이지의 데이터를 요청/ 응답 받기 위한 라이브러리
    -> get 요청 

(2) Beautiful Soup : 정적문서 (HTML, XML 등)를 분석하기 위한 라이브러리 
    -> HTML을 파이썬이 읽기 쉬운 구조로 변환하여 원하는 요소를 구조적으로 추출(Parsing)
       